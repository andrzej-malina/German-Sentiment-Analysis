{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "df_all = pd.read_pickle('df_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing 'rating' column to integer\n",
    "df_all['rating'] = df_all['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_rating = df_all[df_all['rating'] == 1]\n",
    "df_2_rating = df_all[df_all['rating'] == 2]\n",
    "df_3_rating = df_all[df_all['rating'] == 3]\n",
    "df_4_rating = df_all[df_all['rating'] == 4]\n",
    "df_5_rating = df_all[df_all['rating'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17832, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negativ = pd.DataFrame()\n",
    "df_negativ = df_negativ.append(df_1_rating)\n",
    "df_negativ = df_negativ.append(df_2_rating)\n",
    "df_negativ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17832, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positiv = pd.DataFrame()\n",
    "df_positiv = df_positiv.append(df_4_rating)\n",
    "df_positiv = df_positiv.append(df_5_rating)\n",
    "df_positiv = df_positiv.sample(n=17832)\n",
    "df_positiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35664, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "df_all = df_all.append(df_negativ)\n",
    "df_all = df_all.append(df_positiv)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>fullTextHtml</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217280</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;div&gt;\\n  Cover und Titel sind aufeina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219588</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;\"Herbstfunkeln\" ist der erste Teil der \"Cor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170155</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt;Die beiden Autoren Daniel Juhr und...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87185</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;Leider hab ich das Buch nach nicht einmal 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319767</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;span&gt;Rezension zu „Die Duftapothe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                       fullTextHtml  sentiment\n",
       "217280       4  <p></p>\\n<div>\\n  Cover und Titel sind aufeina...          1\n",
       "219588       4  <p>\"Herbstfunkeln\" ist der erste Teil der \"Cor...          1\n",
       "170155       5  <p></p>\\n<p>Die beiden Autoren Daniel Juhr und...          1\n",
       "87185        2  <p>Leider hab ich das Buch nach nicht einmal 1...          0\n",
       "319767       5  <p></p>\\n<p><span>Rezension zu „Die Duftapothe...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['sentiment'] = df_all['rating'].map(lambda x: 0 if x<3 else 1)\n",
    "df_all.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all['fullTextHtml'].values\n",
    "y = df_all['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([13288, 13460], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([4544, 4372], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26748,), (8916,), (26748,), (8916,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x2356ff9f9e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word embeddings with Keras Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "total_reviews = np.concatenate((X_train, X_test))\n",
    "tokenizer.fit_on_texts(total_reviews)\n",
    "\n",
    "#pad sequences\n",
    "review_lengths = [len(s.split()) for s in total_reviews]\n",
    "#pad_length = int(np.mean(review_lengths))\n",
    "pad_length = 100\n",
    "\n",
    "#define vocabulary size\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=pad_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=pad_length, padding='post')\n",
    "\n",
    "\n",
    "#embedding layer\n",
    "embedding_dim =100 #dimension of vector\n",
    "Embedding(vocab_size, embedding_dim, input_length=pad_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          22954500  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,967,301\n",
      "Trainable params: 22,967,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=pad_length),\n",
    "    GRU(units=32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 26748 samples, validate on 8916 samples\n",
      "Epoch 1/5\n",
      " - 191s - loss: 0.4124 - acc: 0.8089 - val_loss: 0.2635 - val_acc: 0.8943\n",
      "Epoch 2/5\n",
      " - 182s - loss: 0.2163 - acc: 0.9218 - val_loss: 0.2441 - val_acc: 0.9023\n",
      "Epoch 3/5\n",
      " - 184s - loss: 0.1336 - acc: 0.9555 - val_loss: 0.2511 - val_acc: 0.9121\n",
      "Epoch 4/5\n",
      " - 188s - loss: 0.0816 - acc: 0.9742 - val_loss: 0.2636 - val_acc: 0.9124\n",
      "Epoch 5/5\n",
      " - 184s - loss: 0.0453 - acc: 0.9865 - val_loss: 0.2992 - val_acc: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2355bfa4d68>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=64, epochs=5, verbose=2, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84106183],\n",
       "       [0.9651642 ],\n",
       "       [0.02035591],\n",
       "       [0.05424052],\n",
       "       [0.9096227 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing on some examples\n",
    "sample_1 = 'Dieser Film ist fantastisch! Er gefällt mir wirklich, weil er so aufregend ist.'\n",
    "sample_2 = 'Sehr schöner Film.'\n",
    "sample_3 = 'Was für ein schlechter Film das war. Ich hätte etwas viel Besseres erwartet.'\n",
    "sample_4 = 'Dieser Film ist wirklich scheiße. Keine Aktion und die Handlung ist flach wie ein Tisch.'\n",
    "sample_5 = 'Sehr interessantes Kino. Tolles Spiel der Schauspieler.'\n",
    "\n",
    "test_samples = [sample_1, sample_2, sample_3, sample_4, sample_5]\n",
    "test_samples_tokens = tokenizer.texts_to_sequences(test_samples)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=pad_length)\n",
    "\n",
    "#predict\n",
    "model.predict(x=test_samples_tokens_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train word2vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first step is to prepare the text corpus for learning the embedding by creating word tokens, removing punctuation, \n",
    "#removing stop words etc. The word2vec algorithm processes documents sentence by sentence.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "review_lines = list()\n",
    "lines = df_all['fullTextHtml'].values.tolist()\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    tokens = tokenizer.tokenize(line)\n",
    "    #convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    #remove tokens that are not alphabetic\n",
    "    tokens = [t for t in tokens if t.isalpha]\n",
    "    #filter out stop words\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    review_lines.append(tokens)\n",
    "    \n",
    "len(review_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is: 206481\n"
     ]
    }
   ],
   "source": [
    "#train word2vec model\n",
    "model = gensim.models.Word2Vec(sentences=review_lines, size=embedding_dim, window=5, workers=4, min_count=1)\n",
    "\n",
    "#vocab size\n",
    "words = list(model.wv.vocab)\n",
    "print ('Vocabulary size is: {}'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('langatmig', 0.8203978538513184),\n",
       " ('uninteressant', 0.7964168787002563),\n",
       " ('eintönig', 0.77809739112854),\n",
       " ('gelangweilt', 0.7662367820739746),\n",
       " ('öde', 0.7570236921310425),\n",
       " ('ermüdend', 0.752723753452301),\n",
       " ('vorhersehbar', 0.7268033027648926),\n",
       " ('zäh', 0.7245047092437744),\n",
       " ('unnötig', 0.7159459590911865),\n",
       " ('abgedreht', 0.7103122472763062)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('langweilig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eingekerkerte', 0.8936576247215271),\n",
       " ('kurfürst', 0.8806434273719788),\n",
       " ('friebert', 0.8764792680740356),\n",
       " ('sklavin', 0.8740070462226868),\n",
       " ('geschichtsstudentin', 0.8692702054977417),\n",
       " ('eismagierin', 0.8690164089202881),\n",
       " ('quichote', 0.8689929842948914),\n",
       " ('königs', 0.8688567876815796),\n",
       " ('herrscher', 0.8683165311813354),\n",
       " ('mächtigen', 0.8673161268234253)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar_cosmul(positive=['frau', 'könig'], negative=['mann'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.wv.save_word2vec_format('w2v_lovelybooks_model', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pre-trained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the word embedding from file\n",
    "embeddings_index ={}\n",
    "f = open(os.path.join('','w2v_lovelybooks_model'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert word embedding into tokenized vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206481 unique tokens.\n",
      "Shape of review sensor:  (35664, 100)\n",
      "Shape of sentiment sensor:  (35664,)\n"
     ]
    }
   ],
   "source": [
    "#vectorize the text samples into a 2D integer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(review_lines)\n",
    "sequences = tokenizer.texts_to_sequences(review_lines)\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word_index)))\n",
    "review_pad = pad_sequences(sequences, maxlen=pad_length)\n",
    "sentiment = df_all['sentiment'].values\n",
    "print('Shape of review sensor: ', review_pad.shape)\n",
    "print('Shape of sentiment sensor: ', sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206482\n"
     ]
    }
   ],
   "source": [
    "#Now we will map embeddings from the loaded word2vec model for each word to the tokenizer.word_index vocabulary \n",
    "#and create a matrix with  word vectors.\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        #words not found in embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          20648200  \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,661,001\n",
      "Trainable params: 12,801\n",
      "Non-trainable params: 20,648,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#We are now ready with the trained embedding vector to be used directly in the embedding layer. \n",
    "#In the below code, the only change from previous model is using the embedding_matrix as input to the Embedding layer \n",
    "#and setting trainable = False, since the embedding is already learned.\n",
    "embedding_layer = Embedding(num_words, \n",
    "                            embedding_dim, \n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=pad_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    GRU(units=32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor:  (26748, 100)\n",
      "Shape of y_train tensor:  (26748,)\n",
      "Shape of X_test_pad tensor:  (8916, 100)\n",
      "Shape of y_test tensor:  (8916,)\n"
     ]
    }
   ],
   "source": [
    "#split the data into training set and validation set\n",
    "validation_split_ratio = 0.25\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "num_validation_samples = int(validation_split_ratio*review_pad.shape[0])\n",
    "\n",
    "X_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train = sentiment[:-num_validation_samples]\n",
    "X_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test = sentiment[-num_validation_samples:]\n",
    "\n",
    "print('Shape of X_train_pad tensor: ', X_train_pad.shape)\n",
    "print('Shape of y_train tensor: ', y_train.shape)\n",
    "print('Shape of X_test_pad tensor: ', X_test_pad.shape)\n",
    "print('Shape of y_test tensor: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([13351, 13397], dtype=int64))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([4481, 4435], dtype=int64))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26748 samples, validate on 8916 samples\n",
      "Epoch 1/10\n",
      " - 43s - loss: 0.5974 - acc: 0.6555 - val_loss: 0.3542 - val_acc: 0.8491\n",
      "Epoch 2/10\n",
      " - 33s - loss: 0.3707 - acc: 0.8368 - val_loss: 0.2766 - val_acc: 0.8859\n",
      "Epoch 3/10\n",
      " - 34s - loss: 0.3137 - acc: 0.8650 - val_loss: 0.2527 - val_acc: 0.8958\n",
      "Epoch 4/10\n",
      " - 35s - loss: 0.2821 - acc: 0.8794 - val_loss: 0.2280 - val_acc: 0.9081\n",
      "Epoch 5/10\n",
      " - 32s - loss: 0.2627 - acc: 0.8892 - val_loss: 0.2185 - val_acc: 0.9125\n",
      "Epoch 6/10\n",
      " - 33s - loss: 0.2514 - acc: 0.8948 - val_loss: 0.2135 - val_acc: 0.9138\n",
      "Epoch 7/10\n",
      " - 31s - loss: 0.2390 - acc: 0.9005 - val_loss: 0.2076 - val_acc: 0.9170\n",
      "Epoch 8/10\n",
      " - 32s - loss: 0.2274 - acc: 0.9055 - val_loss: 0.2040 - val_acc: 0.9178\n",
      "Epoch 9/10\n",
      " - 32s - loss: 0.2259 - acc: 0.9059 - val_loss: 0.1991 - val_acc: 0.9173\n",
      "Epoch 10/10\n",
      " - 33s - loss: 0.2185 - acc: 0.9088 - val_loss: 0.1978 - val_acc: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2355bfb2c50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=10, verbose=2, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
