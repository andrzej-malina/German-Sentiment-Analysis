{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "df_all = pd.read_pickle('df_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing 'rating' column to integer\n",
    "df_all['rating'] = df_all['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_rating = df_all[df_all['rating'] == 1]\n",
    "df_2_rating = df_all[df_all['rating'] == 2]\n",
    "df_3_rating = df_all[df_all['rating'] == 3]\n",
    "df_4_rating = df_all[df_all['rating'] == 4]\n",
    "df_5_rating = df_all[df_all['rating'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17832, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negativ = pd.DataFrame()\n",
    "df_negativ = df_negativ.append(df_1_rating)\n",
    "df_negativ = df_negativ.append(df_2_rating)\n",
    "df_negativ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17832, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positiv = pd.DataFrame()\n",
    "df_positiv = df_positiv.append(df_4_rating)\n",
    "df_positiv = df_positiv.append(df_5_rating)\n",
    "df_positiv = df_positiv.sample(n=df_negativ.shape[0])\n",
    "df_positiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35664, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "df_all = df_all.append(df_negativ)\n",
    "df_all = df_all.append(df_positiv)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>fullTextHtml</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179024</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt;Schwimmen macht Spaß – Jana im Sch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268700</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;span&gt;Was macht man, wenn man nur ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301977</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt;&lt;strong&gt;Inhaltsangabe:&lt;/strong&gt;&lt;br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40184</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;\\n&lt;div&gt;\\n  Achtung, Spoiler bzgl. Teil ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257285</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;&lt;span&gt;\"Dragon Fortune\" &lt;/span&gt;&lt;span&gt;lässt s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                       fullTextHtml  sentiment\n",
       "179024       5  <p></p>\\n<p>Schwimmen macht Spaß – Jana im Sch...          1\n",
       "268700       5  <p></p>\\n<p><span>Was macht man, wenn man nur ...          1\n",
       "301977       4  <p></p>\\n<p><strong>Inhaltsangabe:</strong><br...          1\n",
       "40184        2  <p></p>\\n<div>\\n  Achtung, Spoiler bzgl. Teil ...          0\n",
       "257285       4  <p><span>\"Dragon Fortune\" </span><span>lässt s...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['sentiment'] = df_all['rating'].map(lambda x: 0 if x<3 else 1)\n",
    "df_all.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all['fullTextHtml'].values\n",
    "y = df_all['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8888, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([13374, 13374], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([4458, 4458], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26748,), (8916,), (26748,), (8916,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clear the data and split to tokens\n",
    "def process(seq):\n",
    "    seq = seq.lower()\n",
    "    \n",
    "    punctuations = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    for char in punctuations:\n",
    "        seq = seq.replace(char, ' ')\n",
    "    tokens = seq.split(' ')\n",
    "\n",
    "    stopwords = ['buch', '', 'p', 'br', 'style', 'auf', 'div', 'ul', 'n']\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clearing the data\n",
    "X_train = [process(seq) for seq in X_train]\n",
    "X_test = [process(seq) for seq in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1d02a14def0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word embeddings with Keras Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "total_reviews = np.concatenate((X_train, X_test))\n",
    "tokenizer.fit_on_texts(total_reviews)\n",
    "\n",
    "#pad sequences\n",
    "#review_lengths = [len(s.split()) for s in total_reviews]\n",
    "#pad_length = int(np.mean(review_lengths))\n",
    "pad_length = 100\n",
    "\n",
    "#define vocabulary size\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=pad_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=pad_length, padding='post')\n",
    "\n",
    "\n",
    "#embedding layer\n",
    "embedding_dim =100 #dimension of vector\n",
    "Embedding(vocab_size, embedding_dim, input_length=pad_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          22912700  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,925,501\n",
      "Trainable params: 22,925,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=pad_length),\n",
    "    GRU(units=32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 26748 samples, validate on 8916 samples\n",
      "Epoch 1/5\n",
      " - 219s - loss: 0.3839 - acc: 0.8240 - val_loss: 0.2903 - val_acc: 0.8766\n",
      "Epoch 2/5\n",
      " - 215s - loss: 0.2034 - acc: 0.9275 - val_loss: 0.2219 - val_acc: 0.9145\n",
      "Epoch 3/5\n",
      " - 214s - loss: 0.1315 - acc: 0.9561 - val_loss: 0.2473 - val_acc: 0.9104\n",
      "Epoch 4/5\n",
      " - 193s - loss: 0.0789 - acc: 0.9735 - val_loss: 0.2467 - val_acc: 0.9118\n",
      "Epoch 5/5\n",
      " - 187s - loss: 0.0501 - acc: 0.9834 - val_loss: 0.2737 - val_acc: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d01cc5f198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=64, epochs=5, verbose=2, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6984233 ],\n",
       "       [0.97958404],\n",
       "       [0.00228065],\n",
       "       [0.0195238 ],\n",
       "       [0.99113816]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing on some examples\n",
    "sample_1 = 'Dieser Film ist fantastisch! Er gefällt mir wirklich, weil er so aufregend ist.'\n",
    "sample_2 = 'Sehr schöner Film.'\n",
    "sample_3 = 'Was für ein schlechter Film das war. Ich hätte etwas viel Besseres erwartet.'\n",
    "sample_4 = 'Dieser Film ist wirklich scheiße. Keine Aktion und die Handlung ist flach wie ein Tisch.'\n",
    "sample_5 = 'Sehr interessantes Kino. Tolles Spiel der Schauspieler.'\n",
    "\n",
    "test_samples = [sample_1, sample_2, sample_3, sample_4, sample_5]\n",
    "test_samples_tokens = tokenizer.texts_to_sequences(test_samples)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=pad_length)\n",
    "\n",
    "#predict\n",
    "model.predict(x=test_samples_tokens_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train word2vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35664"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first step is to prepare the text corpus for learning the embedding by creating word tokens, removing punctuation, \n",
    "#removing stop words etc. The word2vec algorithm processes documents sentence by sentence.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "review_lines = list()\n",
    "lines = df_all['fullTextHtml'].values.tolist()\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    tokens = tokenizer.tokenize(line)\n",
    "    #convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    #remove tokens that are not alphabetic\n",
    "    tokens = [t for t in tokens if t.isalpha]\n",
    "    #filter out stop words\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    review_lines.append(tokens)\n",
    "    \n",
    "len(review_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is: 205903\n"
     ]
    }
   ],
   "source": [
    "#train word2vec model\n",
    "model = gensim.models.Word2Vec(sentences=review_lines, size=embedding_dim, window=5, workers=4, min_count=1)\n",
    "\n",
    "#vocab size\n",
    "words = list(model.wv.vocab)\n",
    "print ('Vocabulary size is: {}'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('langatmig', 0.8075939416885376),\n",
       " ('uninteressant', 0.7792505025863647),\n",
       " ('gelangweilt', 0.7586060762405396),\n",
       " ('öde', 0.7402040958404541),\n",
       " ('eintönig', 0.7377558350563049),\n",
       " ('ermüdend', 0.7332887053489685),\n",
       " ('unnötig', 0.7288734912872314),\n",
       " ('vorhersehbar', 0.7247648239135742),\n",
       " ('langgezogen', 0.7162354588508606),\n",
       " ('unspektakulär', 0.7069278955459595)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('langweilig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kurfürst', 0.9012632369995117),\n",
       " ('herbalistin', 0.888185977935791),\n",
       " ('königs', 0.882672131061554),\n",
       " ('coolste', 0.8804940581321716),\n",
       " ('krieger', 0.8790843486785889),\n",
       " ('königin', 0.8789700865745544),\n",
       " ('ledige', 0.8754025101661682),\n",
       " ('prinzessin', 0.8716257214546204),\n",
       " ('mächtigen', 0.8710815906524658),\n",
       " ('militärakademie', 0.8694743514060974)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar_cosmul(positive=['frau', 'könig'], negative=['mann'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajankowski\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.wv.save_word2vec_format('w2v_lovelybooks_model', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pre-trained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the word embedding from file\n",
    "embeddings_index ={}\n",
    "f = open(os.path.join('','w2v_lovelybooks_model'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert word embedding into tokenized vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 205903 unique tokens.\n",
      "Shape of review tensor:  (35664, 100)\n",
      "Shape of sentiment tensor:  (35664,)\n"
     ]
    }
   ],
   "source": [
    "#vectorize the text samples into a 2D integer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(review_lines)\n",
    "sequences = tokenizer.texts_to_sequences(review_lines)\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word_index)))\n",
    "review_pad = pad_sequences(sequences, maxlen=pad_length)\n",
    "sentiment = df_all['sentiment'].values\n",
    "print('Shape of review tensor: ', review_pad.shape)\n",
    "print('Shape of sentiment tensor: ', sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205904\n"
     ]
    }
   ],
   "source": [
    "#Now we will map embeddings from the loaded word2vec model for each word to the tokenizer.word_index vocabulary \n",
    "#and create a matrix with  word vectors.\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        #words not found in embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          20590400  \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,603,201\n",
      "Trainable params: 12,801\n",
      "Non-trainable params: 20,590,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#We are now ready with the trained embedding vector to be used directly in the embedding layer. \n",
    "#In the below code, the only change from previous model is using the embedding_matrix as input to the Embedding layer \n",
    "#and setting trainable = False, since the embedding is already learned.\n",
    "embedding_layer = Embedding(num_words, \n",
    "                            embedding_dim, \n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=pad_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    GRU(units=32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor:  (26748, 100)\n",
      "Shape of y_train tensor:  (26748,)\n",
      "Shape of X_test_pad tensor:  (8916, 100)\n",
      "Shape of y_test tensor:  (8916,)\n"
     ]
    }
   ],
   "source": [
    "#split the data into training set and validation set\n",
    "validation_split_ratio = 0.25\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "num_validation_samples = int(validation_split_ratio*review_pad.shape[0])\n",
    "\n",
    "X_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train = sentiment[:-num_validation_samples]\n",
    "X_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test = sentiment[-num_validation_samples:]\n",
    "\n",
    "print('Shape of X_train_pad tensor: ', X_train_pad.shape)\n",
    "print('Shape of y_train tensor: ', y_train.shape)\n",
    "print('Shape of X_test_pad tensor: ', X_test_pad.shape)\n",
    "print('Shape of y_test tensor: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([13350, 13398], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([4482, 4434], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26748 samples, validate on 8916 samples\n",
      "Epoch 1/10\n",
      " - 24s - loss: 0.5582 - acc: 0.6960 - val_loss: 0.3316 - val_acc: 0.8574\n",
      "Epoch 2/10\n",
      " - 17s - loss: 0.3633 - acc: 0.8415 - val_loss: 0.2718 - val_acc: 0.8868\n",
      "Epoch 3/10\n",
      " - 20s - loss: 0.3062 - acc: 0.8690 - val_loss: 0.2505 - val_acc: 0.8956\n",
      "Epoch 4/10\n",
      " - 18s - loss: 0.2808 - acc: 0.8816 - val_loss: 0.2364 - val_acc: 0.9025\n",
      "Epoch 5/10\n",
      " - 18s - loss: 0.2595 - acc: 0.8902 - val_loss: 0.2165 - val_acc: 0.9107\n",
      "Epoch 6/10\n",
      " - 24s - loss: 0.2507 - acc: 0.8974 - val_loss: 0.2076 - val_acc: 0.9155\n",
      "Epoch 7/10\n",
      " - 23s - loss: 0.2376 - acc: 0.9022 - val_loss: 0.2094 - val_acc: 0.9124\n",
      "Epoch 8/10\n",
      " - 22s - loss: 0.2354 - acc: 0.9022 - val_loss: 0.2024 - val_acc: 0.9154\n",
      "Epoch 9/10\n",
      " - 20s - loss: 0.2298 - acc: 0.9049 - val_loss: 0.1986 - val_acc: 0.9188\n",
      "Epoch 10/10\n",
      " - 19s - loss: 0.2215 - acc: 0.9063 - val_loss: 0.1958 - val_acc: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d092e3ff98>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=10, verbose=2, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
